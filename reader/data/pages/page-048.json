{
  "page": 48,
  "title": "Scientific Discovery Agents",
  "content": "<div class=\"article-header\">\n                        <div class=\"section-label\">Section 6.2 &middot; Scientific Discovery</div>\n                        <h1>Scientific Discovery Agents</h1>\n                    </div>\n                    <div class=\"original-content\">\n                        <p>Scientific-discovery agents aim to accelerate the entire life cycle for scientific research, from hypothesis generation through experimental execution, by coupling LLMs with domain-specific simulators, laboratory automation and up-to-date literature. These systems ground decision in verifiable processes while handling heterogeneous data, safety constraints and long-horizon goals.</p>\n                        <p>In this subsection, we begin with the foundational layer (Section 6.2.1), which encompasses planning under scientific context, tool-augmented interaction with scientific resources, search and retrieval mechanisms including RAG-based systems and execution-time integration with laboratory hardware. Building upon these capabilities, the self-evolving layer (Section 6.2.2) introduces agentic memory, feedback and reflection, which enable scientific agents to refine hypotheses, adapt protocols and learn from experimental outcomes.</p>\n                        <p>Finally, the collective layer (Section 6.2.3) explores multi-agent collaboration, where agents coordinate roles, share intermediate knowledge and jointly reason toward complex scientific goals.</p>\n                        <h3>6.2.1. Foundational Agentic Reasoning</h3>\n                        <p><strong>Planning.</strong> Scientific agents utilize reasoning-enhanced planning ability to decompose a research goal into steps, decides which tool or simulator to call next, then revises the plan as evidence arrives. In short, the <em>chain of thought</em> emerges from LLM reasoning that compiles instructions into rigorous executable plans.</p>\n                        <p>For example, ProAgent [507] materializes a planner agent that utilizes LLM reasoning capability to formulate a concrete plan for protein analysis and keep modifying it with feedback from another critic agent, and Eunomia [508] uses ReAct-style workflow to make in-context reasoning: after retrieving a top-k evidence set, the backbone LLM quote a warranting sentence, and that citation drives the next action choice.</p>\n                    </div>\n                    <div class=\"analysis-section\">\n                        <h3>Analysis & Explanation</h3>\n                        <div class=\"analysis-block\">\n                            <h4>Scientific Agent Capabilities</h4>\n                            <div class=\"analysis-item\">\n                                <h5>Core Functions</h5>\n                                <ul>\n                                    <li><strong>Hypothesis Generation:</strong> Proposing testable scientific ideas</li>\n                                    <li><strong>Experimental Design:</strong> Planning verification procedures</li>\n                                    <li><strong>Literature Integration:</strong> Grounding in existing knowledge</li>\n                                    <li><strong>Lab Automation:</strong> Interfacing with physical equipment</li>\n                                </ul>\n                            </div>\n                        </div>\n                    </div>"
}