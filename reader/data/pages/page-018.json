{
  "page": 18,
  "title": "Agentic Search (Figure 4)",
  "content": "<div class=\"article-header\">\n                        <div class=\"section-label\">Section 3.3 &middot; Agentic Search</div>\n                        <h1>Agentic Search Systems</h1>\n                    </div>\n                    <div class=\"original-content\">\n                        <div class=\"figure-box\">\n                            <h4>Figure 4: Traditional RAG vs Agentic Search Systems</h4>\n                            <p><strong>Traditional RAG System (Left):</strong></p>\n                            <ul>\n                                <li>Query → Data Embedding → Static retrieval over vector database</li>\n                                <li>Single-shot retrieval, no iteration</li>\n                            </ul>\n                            <p><strong>Agentic Search System (Right):</strong></p>\n                            <ul>\n                                <li>Dynamic search + In-context Search + Search SFT/RL</li>\n                                <li>WHEN/WHAT, HOW to Retrieve → Autonomous Agent</li>\n                                <li>Tool Use + Reasoning + Critique & Adapt</li>\n                                <li>Experience from web → Iterative refinement</li>\n                            </ul>\n                        </div>\n                        <p>Single-agent Agentic Retrieval-Augmented Generation (RAG) systems embed reasoning and control into a centralized agent that governs the entire retrieval-generation loop. Unlike traditional RAG pipelines that perform fixed, one-shot retrieval before generation, agentic RAG agents dynamically control <em>when</em>, <em>what</em>, and <em>how</em> to retrieve based on real-time reasoning needs.</p>\n                        <h3>3.3.1 In-Context Search</h3>\n                        <h3>Interleaving Reasoning and Search</h3>\n                        <p>In-context agentic RAG systems embed retrieval behavior directly into the inference process of language models through carefully designed prompting strategies. A representative example is <strong>ReAct</strong>, which interleaves Chain-of-Thought reasoning with tool-use commands such as &lt;Search&gt; to dynamically invoke external APIs or knowledge sources.</p>\n                    </div>\n                    <div class=\"analysis-section\">\n                        <h3>Analysis & Explanation</h3>\n                        <div class=\"analysis-block\">\n                            <h4>RAG Evolution</h4>\n                            <div class=\"analysis-item\">\n                                <h5>From Static to Agentic</h5>\n                                <p>Traditional RAG: \"Retrieve first, then generate.\" Agentic RAG: \"Reason about what to retrieve, when to retrieve, iterate, and verify.\" This shift enables handling of complex, multi-hop questions that require iterative refinement.</p>\n                            </div>\n                        </div>\n                    </div>"
}