{
  "page": 68,
  "title": "Planning and Feedback Benchmarks",
  "content": "<div class=\"article-header\">\n                        <div class=\"section-label\">Section 7.1.3 &middot; Planning (continued)</div>\n                        <h1>Planning and Feedback Benchmarks</h1>\n                    </div>\n                    <div class=\"original-content\">\n                        <h3>Planning and Feedback</h3>\n                        <p>Benchmarks targeting planning and feedback primarily assess whether agents can effectively utilize memory to support multi-step planning based on environmental feedback, and maintain coherent internal state over extended interactions. First, ALFWorld [48] employs interactive environments to evaluate the consistency of multi-step planning, requiring agents to accumulate observations across actions and maintain latent internal states throughout execution.</p>\n                        <p>Moreover, formal planning benchmarks such as PlanBench [723] and ACPBench [724] assess planning capabilities in explicitly defined dynamic environments, testing whether agents can correctly reason about action preconditions, effects, reachability, and overall plan validity. TEXT2WORLD [725] integrates fragmented textual descriptions into a coherent and executable world model, evaluating the capacity to continuously consolidate historical facts into structured planning representations.</p>\n                        <p>More recent benchmarks place greater emphasis on feedback integration and planning under non-stationary conditions. For example, REALM-Bench [726] introduces dynamic disturbances in real-world manufacturing scenarios, requiring agents to remember prior commitments and replan when underlying assumptions are violated, while TravelPlanner [727] focuses on accurate itinerary construction under constrained and evolving information.</p>\n                        <h3>7.1.4. Multi-Agent System</h3>\n                        <p>To evaluate coordination, competition, and decision making beyond isolated reasoning, recent benchmarks situate multi-agent systems in interactive environments. These works broadly span game-based evaluations, simulation-centric real-world scenarios, and language-driven social reasoning tasks.</p>\n                        <h3>Game-based Reinforcement Learning Evaluation</h3>\n                        <p>Game-based reinforcement learning evaluation benchmarks leverage classical and novel gaming environments to systematically compare the performance of multi-agent RL algorithms under cooperative and adversarial settings. MAgent [730] facilitates massive-scale multi-agent scenarios such as pursuit and resource competition within customizable grid-worlds, evaluating individual cumulative rewards and competitive metrics like resource occupancy rates.</p>\n                    </div>\n                    <div class=\"analysis-section\">\n                        <h3>Analysis & Explanation</h3>\n                        <div class=\"analysis-block\">\n                            <h4>Planning Benchmark Features</h4>\n                            <div class=\"analysis-item\">\n                                <h5>Key Challenges</h5>\n                                <ul>\n                                    <li><strong>Multi-Step Consistency:</strong> Maintaining coherent plans</li>\n                                    <li><strong>Dynamic Environments:</strong> Adapting to changes</li>\n                                    <li><strong>Feedback Integration:</strong> Learning from execution results</li>\n                                    <li><strong>Constraint Satisfaction:</strong> Meeting complex requirements</li>\n                                </ul>\n                            </div>\n                        </div>\n                    </div>"
}