{
  "page": 84,
  "title": "References (Part 10)",
  "content": "<div class=\"article-header\">\n                        <div class=\"section-label\">References</div>\n                        <h1>References (Part 10)</h1>\n                    </div>\n                    <div class=\"original-content\">\n                        <h3>Continued References [132-144]</h3>\n                        <ul>\n                            <li><strong>[132]</strong> Antonis Antoniades et al. - Swe-search: Enhancing software agents with monte carlo tree search and iterative refinement (2024)</li>\n                            <li><strong>[133]</strong> Artem Lykov and Dzmitry Tsetserukoy - Llm-brain: AI-driven fast generation of robot behaviour tree based on large language model (2024)</li>\n                            <li><strong>[134]</strong> Yue Cao and CS Lee - Robot behavior-tree-based task generation with large language models (2023)</li>\n                            <li><strong>[135]</strong> Riccardo Andrea Izzo et al. - Btgenbot: Behavior tree generation for robotic tasks with lightweight llms (2024)</li>\n                            <li><strong>[136]</strong> Michael Ahn et al. - Do as I can, not as I say: Grounding language in robotic affordances (2022)</li>\n                            <li><strong>[137]</strong> Wenlong Huang et al. - Inner monologue: Embodied reasoning through planning with language models (2023)</li>\n                            <li><strong>[138]</strong> Lin Guan et al. - Leveraging pre-trained large language models to construct and utilize world models for model-based task planning (2024)</li>\n                            <li><strong>[139]</strong> Sadegh Mahdavi et al. - Leveraging environment interaction for automated pdrl translation and planning with large language models (2024)</li>\n                            <li><strong>[140]</strong> Michael Katz et al. - Thought of search: Planning with language models through the lens of efficiency (2024)</li>\n                            <li><strong>[141]</strong> Yilun Hao et al. - Planning anything with rigor: General-purpose zero-shot planning with llm-based formalized programming (2024)</li>\n                            <li><strong>[142]</strong> Kaustubh Vyas et al. - From an llm swarm to a pddl-empowered hive: Planning self-executed instructions in a multi-modal jungle (2024)</li>\n                            <li><strong>[143]</strong> Yuji Zhang et al. - Atomic reasoning for scientific table claim verification (2025)</li>\n                            <li><strong>[144]</strong> Zibin Dong et al. - Diffuserlite: Towards real-time diffusion planning (2024)</li>\n                        </ul>\n                    </div>\n                    <div class=\"analysis-section\">\n                        <h3>Analysis & Explanation</h3>\n                        <div class=\"analysis-block\">\n                            <h4>Robotics and Embodied Planning</h4>\n                            <div class=\"analysis-item\">\n                                <h5>Research Areas</h5>\n                                <ul>\n                                    <li><strong>Behavior Trees:</strong> LLM-generated robot behaviors</li>\n                                    <li><strong>World Models:</strong> Pre-trained models for planning</li>\n                                    <li><strong>PDDL Integration:</strong> Formal planning with LLMs</li>\n                                </ul>\n                            </div>\n                        </div>\n                    </div>"
}