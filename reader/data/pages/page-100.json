{
  "page": 100,
  "title": "References (Part 26)",
  "content": "<div class=\"article-header\">\n                        <div class=\"section-label\">References</div>\n                        <h1>References (Part 26)</h1>\n                    </div>\n                    <div class=\"original-content\">\n                        <h3>Continued References [336-349]</h3>\n                        <ul>\n                            <li><strong>[336]</strong> Toby Simonds et al. - Self rewarding self improving (2025)</li>\n                            <li><strong>[337]</strong> Jiangqiao Lu et al. - Self: Self-evolution with language feedback (2023)</li>\n                            <li><strong>[338]</strong> Aviral Kumar et al. - Training language models to self-correct via reinforcement learning (2024)</li>\n                            <li><strong>[339]</strong> Mert Yuksekgonul et al. - Textgrad: Automatic \"differentiation\" via text (2024)</li>\n                            <li><strong>[340]</strong> Tevin Wang and Chenyu Xiong - Autorule: Reasoning chain-of-thought extracted rule-based rewards improve preference learning (2025)</li>\n                            <li><strong>[341]</strong> Mengkang Hu et al. - Agentgen: Enhancing planning abilities for large language model based agent via environment and task generation (2025)</li>\n                            <li><strong>[342]</strong> Haotian Sun et al. - Adaplanner: Adaptive planning from feedback with language models (2023)</li>\n                            <li><strong>[343]</strong> Maxime Robeyns et al. - A self-improving coding agent (2025)</li>\n                            <li><strong>[344]</strong> Zihan Wang et al. - Ragen: Understanding self-evolution in llm agents via multi-turn reinforcement learning (2025)</li>\n                            <li><strong>[345]</strong> Borui Wang et al. - Dystil: Dynamic strategy induction with large language models for reinforcement learning (2025)</li>\n                            <li><strong>[346]</strong> Tianle Cai et al. - Large language models as tool makers (2024)</li>\n                            <li><strong>[347]</strong> Lifan Yuan et al. - CRAFT: Customizing LLMs by creating and retrieving from specialized toolsets (2024)</li>\n                            <li><strong>[348]</strong> Cheng Qian et al. - CREATOR: Tool creation for disentangling abstract and concrete reasoning of large language models (2023)</li>\n                            <li><strong>[349]</strong> Georg WÃ¶lflein et al. - Llm agents making agent tools (2025)</li>\n                        </ul>\n                    </div>\n                    <div class=\"analysis-section\">\n                        <h3>Analysis & Explanation</h3>\n                        <div class=\"analysis-block\">\n                            <h4>Self-Evolution and Tool Creation</h4>\n                            <div class=\"analysis-item\">\n                                <h5>Key Contributions</h5>\n                                <ul>\n                                    <li><strong>Self-Correction:</strong> RL-based self-improvement</li>\n                                    <li><strong>TextGrad:</strong> Text-based differentiation</li>\n                                    <li><strong>Tool Makers:</strong> LLMs creating their own tools</li>\n                                </ul>\n                            </div>\n                        </div>\n                    </div>"
}