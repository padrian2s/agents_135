{
  "page": 53,
  "title": "Embodied Agents: Self-Evolving Reasoning",
  "content": "<div class=\"article-header\">\n                        <div class=\"section-label\">Section 6.3.2 &middot; Self-Evolving Embodied</div>\n                        <h1>Self-Evolving Agentic Reasoning for Embodied Agents</h1>\n                    </div>\n                    <div class=\"original-content\">\n                        <h3>Search and Retrieval</h3>\n                        <p>Embodied agents can also use search and retrieval ability to ground language in spatial structure and past experience. Early navigation systems such as L3MVN [562] use LLMs to query a semantic map and select promising frontiers as long-term goals during visual target navigation, while SayNav [563] and SayPlan [541] build 3D scene graphs and then search task-relevant subgraphs so language instructions can be translated into grounded waypoints and sub-tasks in large environments.</p>\n                        <p>Long-horizon navigation works like ReMEmbR [564] maintain a structured spatio-temporal memory that can be queried to answer \"where\" and \"when\" questions about past robot experience. Additionally, RAG-style systems make retrieval a first-class part of the planning loop; Embodied-RAG [565] and EmbodiedRAG [57] treat an agent's experience and 3D scene graphs as non-parametric memories from which task-relevant episodes or subgraphs are retrieved for navigation and task planning.</p>\n                        <h3>6.3.2. Self-evolving Agentic Reasoning</h3>\n                        <p>Embodied agents reliably achieve long-horizon autonomy when they can self-evolve over time: monitor their own internal states, store and update task-relevant knowledge and adjust behaviors when plans deviate. In the following paragraphs, we examine how memory modules, feedback signals and agentic reflection enable embodied agents to turn planning from a one-shot process into a continually improving cycle of behavior.</p>\n                        <h3>Memory</h3>\n                        <p>Effective memory mechanisms enable agents to reuse past experiences and maintain coherent task execution over extended interactions. Many systems cache recent observations in episodic buffers while summarizing long-term semantics in structured graphs, as in household planning [568] and long-horizon agents with hybrid multi-modal memory [507]. Skills and routines can be shared across tasks via indexed memory stores.</p>\n                        <p>For example, HELPER-X [569] indexes discovered skills and action scripts, while at future dialogue and can be shared across domains. Spatial navigation methods such as BrainNav [570] maintain biologically inspired dual-map memories linked by a hippocampal hub to reduce hallucinations and drift.</p>\n                    </div>\n                    <div class=\"analysis-section\">\n                        <h3>Analysis & Explanation</h3>\n                        <div class=\"analysis-block\">\n                            <h4>Embodied Memory Systems</h4>\n                            <div class=\"analysis-item\">\n                                <h5>Memory Types</h5>\n                                <ul>\n                                    <li><strong>Episodic:</strong> Recent observations and experiences</li>\n                                    <li><strong>Semantic:</strong> Long-term knowledge graphs</li>\n                                    <li><strong>Spatial:</strong> Maps and navigation history</li>\n                                    <li><strong>Skill Library:</strong> Reusable action sequences</li>\n                                </ul>\n                            </div>\n                        </div>\n                    </div>"
}