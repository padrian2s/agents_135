{
  "page": 14,
  "title": "Tool-Use Optimization (Table 3)",
  "content": "<div class=\"article-header\">\n                        <div class=\"section-label\">Section 3.2 &middot; Tool Use</div>\n                        <h1>Tool-Use Optimization</h1>\n                    </div>\n                    <div class=\"original-content\">\n                        <p>Tool use optimization is the capacity of an agent to augment its intrinsic capabilities by intelligently invoking external modules. This allows agents to overcome limitations such as outdated knowledge, inability to perform precise calculations, or lack of access to private information.</p>\n                        <div class=\"highlight-box\">\n                            <h4>Table 3: Representative Tool-Use Optimization Systems</h4>\n                            <table class=\"data-table\">\n                                <tr><th>Method</th><th>Stage</th><th>Learning</th><th>Tool Strategy</th></tr>\n                                <tr><td colspan=\"4\"><strong>Modality I: In-Context Integration</strong></td></tr>\n                                <tr><td>ReAct</td><td>Inference</td><td>Prompting</td><td>Interleaved reasoning-action</td></tr>\n                                <tr><td>ART</td><td>Inference</td><td>Few-shot</td><td>Retrieved multi-step demos</td></tr>\n                                <tr><td>ChatCoT</td><td>Inference</td><td>Prompting</td><td>CoT with tool calls</td></tr>\n                                <tr><td>GEAR</td><td>Inference</td><td>Delegation</td><td>Light model for tool selection</td></tr>\n                                <tr><td>AVATAR</td><td>Inference</td><td>Contrastive</td><td>In-context tool reasoning</td></tr>\n                                <tr><td colspan=\"4\"><strong>Modality II: Post-Training Integration</strong></td></tr>\n                                <tr><td>Toolformer</td><td>Post-train</td><td>Self-sup. + SFT</td><td>Self-generated API calls</td></tr>\n                                <tr><td>ToolLLM</td><td>Post-train</td><td>SFT</td><td>Large-scale API demos</td></tr>\n                                <tr><td>ToolAlpaca</td><td>Post-train</td><td>SFT</td><td>Simulated dialogues</td></tr>\n                                <tr><td>ReSearch</td><td>Post-train</td><td>RL + Reflec.</td><td>Adaptive retrieval reasoning</td></tr>\n                                <tr><td>ToolRL</td><td>Post-train</td><td>RL</td><td>Multi-tool policy learning</td></tr>\n                            </table>\n                        </div>\n                        <h3>3.2.1 In-Context Tool-integration</h3>\n                        <p>The in-context demonstration paradigm is a training-free approach to empowering LLMs with new capabilities at inference time. This method leverages the remarkable in-context learning ability of modern LLMs, guiding a frozen, off-the-shelf model to perform complex tasks by providing carefully crafted instructions, examples, and contextual information directly in the prompt.</p>\n                    </div>\n                    <div class=\"analysis-section\">\n                        <h3>Analysis & Explanation</h3>\n                        <div class=\"analysis-block\">\n                            <h4>Tool Use Patterns</h4>\n                            <div class=\"analysis-item\">\n                                <h5>Implementation Approaches</h5>\n                                <ul>\n                                    <li><strong>ReAct pattern:</strong> Thought → Action → Observation loop</li>\n                                    <li><strong>Toolformer pattern:</strong> Model learns when/how to call tools during training</li>\n                                    <li><strong>Orchestration pattern:</strong> External system manages tool selection and execution</li>\n                                </ul>\n                            </div>\n                        </div>\n                    </div>"
}