{
  "page": 61,
  "title": "Web Agents: Self-Evolving Reasoning",
  "content": "<div class=\"article-header\">\n                        <div class=\"section-label\">Section 6.5.2 &middot; Self-Evolving Web Agents</div>\n                        <h1>Self-Evolving Agentic Reasoning for Web Agents</h1>\n                    </div>\n                    <div class=\"original-content\">\n                        <h3>6.5.2. Self-evolving Agentic Reasoning</h3>\n                        <p>Effective self-evolving abilities enable these autonomous agents to adapt their behavior over time, retain crucial task context across interaction cycles and incrementally refine planning and execution strategies. The following paragraphs review how memory, feedback and self-reflection mechanisms support this continual improvement across these agent families, turning interaction from a one-shot pipeline into an iterative learning loop.</p>\n                        <h3>Memory</h3>\n                        <p>Memory modules transform brittle, single-pass web interactions into reusable experience. For example, Agent Workflow Memory (AWM) [298] induces reusable workflows from successful trajectories and retrieves them to guide future tasks, while SCaL [660] distils noisy trajectories into high-level verbal and visual abstractions that are stored as a memory of multimodal experience and later injected into prompts.</p>\n                        <p>Control-oriented designs such as BrowserAgent [639] maintain explicit histories of past actions and intermediate conclusions in the agent's context, instead of only re-encoding the current page view. GLM-based agents like AutoWebGLM [605] and AgentOccam [661] emphasize compressed page representations, using HTML simplification and carefully tuned observation spaces so that the agent's prompt contains a shorter, more informative view of the state, with past steps preserved through the usual action-observation history.</p>\n                        <p>Recent GUI agents adopt explicit memory modules that store and retrieve task-relevant information during long-horizon execution. Earlier work such as MobileGPT [663] equips a mobile assistant with human-like app memory: it decomposes procedures into modular sub-tasks that are explored, selected, derived, and then stored so they can be recalled and reused instead of being re-discovered from scratch.</p>\n                    </div>\n                    <div class=\"analysis-section\">\n                        <h3>Analysis & Explanation</h3>\n                        <div class=\"analysis-block\">\n                            <h4>Web Agent Memory Patterns</h4>\n                            <div class=\"analysis-item\">\n                                <h5>Memory Types</h5>\n                                <ul>\n                                    <li><strong>Workflow Memory:</strong> Reusable task procedures</li>\n                                    <li><strong>Multimodal Abstraction:</strong> Visual + verbal experience</li>\n                                    <li><strong>Action History:</strong> Sequential interaction records</li>\n                                    <li><strong>Compressed State:</strong> Efficient page representations</li>\n                                </ul>\n                            </div>\n                        </div>\n                    </div>"
}