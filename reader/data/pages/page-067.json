{
  "page": 67,
  "title": "Memory and Planning Benchmarks",
  "content": "<div class=\"article-header\">\n                        <div class=\"section-label\">Section 7.1.3 &middot; Memory and Planning</div>\n                        <h1>Memory and Planning Benchmarks</h1>\n                    </div>\n                    <div class=\"original-content\">\n                        <h3>7.1.3. Memory and Planning</h3>\n                        <p>A distinctive advantage of agents lies in their ability to leverage memory to achieve accurate long-term performance and strong reasoning capabilities. This ability can be assessed from two complementary perspectives. The first concerns memory management, which reflects how effectively an agent integrates, organizes, and retrieves long-term memories. The second concerns memory utilization, which captures how well an agent exploits historical information to support planning and informed feedback.</p>\n                        <h3>Long-Horizon Episodic Memory</h3>\n                        <p>This category targets single-episode tasks with partial observability and delayed rewards, requiring agents to store and retrieve information over extended time spans. Benchmarks in this space evaluate memory retention, retrieval, and reasoning across long contexts. PertLTQA [712] simulates personalized dialogue, where agents answer questions using long-term personas and event memories. It includes 8.5K QA pairs and evaluates memory classification, retrieval ranking, and synthesis fidelity.</p>\n                        <p>ELITEBench [713] tests QA on noisy meeting transcripts, where relevant evidence may appear far earlier than the query. Models are scored via GPT-4 across various ASR noise levels and dialogue settings. In the meanwhile, Multi-IF [714] and MultiChallenge [715] focus on multi-turn instruction following. Multi-IF [714] spans 4.5K tri-turn conversations in 8 languages, with evaluation based on strict and relaxed instruction accuracy. MultiChallenge [715] tests four memory-intensive phenomena: retention, inference, editing, and coherence, using 273 curated dialogues with binary pass/fail evaluation.</p>\n                        <h3>Multi-session Recall</h3>\n                        <p>Multi-session Recall focuses on multi-episode tasks where agents must retain and integrate knowledge across separate sessions, supporting lifelong adaptation and mitigating catastrophic forgetting. A range of recent benchmarks systematically probe this capability under realistic, long-term interaction scenarios.</p>\n                    </div>\n                    <div class=\"analysis-section\">\n                        <h3>Analysis & Explanation</h3>\n                        <div class=\"analysis-block\">\n                            <h4>Memory Benchmark Types</h4>\n                            <div class=\"analysis-item\">\n                                <h5>Evaluation Dimensions</h5>\n                                <ul>\n                                    <li><strong>Long-Horizon Episodic:</strong> Single-episode retention over time</li>\n                                    <li><strong>Multi-Session Recall:</strong> Cross-session knowledge integration</li>\n                                    <li><strong>Memory Management:</strong> Organization and retrieval efficiency</li>\n                                    <li><strong>Memory Utilization:</strong> Using history for planning</li>\n                                </ul>\n                            </div>\n                        </div>\n                    </div>"
}