{
  "page": 69,
  "title": "Multi-Agent System Benchmarks",
  "content": "<div class=\"article-header\">\n                        <div class=\"section-label\">Section 7.1.4 &middot; Multi-Agent</div>\n                        <h1>Multi-Agent System Benchmarks</h1>\n                    </div>\n                    <div class=\"original-content\">\n                        <h3>Game-based Evaluation (continued)</h3>\n                        <p>Pommerman [731] adapts the classic Bomberman game for cooperative and adversarial interactions, quantifying performance through win rates, survival duration, and kill-to-suicide ratio. SMAC [732] centers on decentralized micro-management challenges in StarCraft II scenarios, evaluating team success via win rates, average damage output, and formation dispersion.</p>\n                        <p>MineLand [733] utilizes Minecraft as a realistic ecological simulation for large-scale multi-agent coordination, with up to 64 agents cooperating to meet physical needs under partial observability. TeamCraft [734] also employs Minecraft to benchmark embodied multi-modal agents tasked with interpreting visual, textual, and environmental prompts to collaboratively achieve 55,000 procedurally generated task instances.</p>\n                        <p>Melting Pot [735] assesses agents' zero-shot generalization capabilities in diverse social dilemma environments, utilizing metrics such as per-capita return, social welfare, and inequality indices. BenchMARL [736] provides standardized algorithm comparisons across multiple scenarios (e.g., SMACv2, VMAS, MRL), measuring convergence rates, final performance, and hyperparameter sensitivity. Finally, Arena [737] encompasses a comprehensive suite of cooperative and adversarial games across various complexities, evaluating individual returns, collective social welfare, and emergent communication protocols.</p>\n                        <h3>Simulation-centric Real-world Assessment</h3>\n                        <p>Simulation-centric real-world benchmarks simulate realistic or pseudo-realistic environments, emphasizing scalability, partial observability, and dynamic planning. SMARTS [738] offers a scalable multi-agent driving platform for real-world traffic scenarios like merges and intersections, with evaluation based on collision rates, task completion, and agent behavior distributions.</p>\n                        <p>Nocturne [739] provides high-throughput, partially observable driving simulations using Waymo trajectories, testing coordination and human-like behavior in tasks such as intersections and roundabouts. MARBL [740] benchmarks multi-echelon inventory management, simulating cooperative and competitive retail dynamics, evaluated via profit metrics across diverse inventory settings.</p>\n                    </div>\n                    <div class=\"analysis-section\">\n                        <h3>Analysis & Explanation</h3>\n                        <div class=\"analysis-block\">\n                            <h4>Multi-Agent Benchmark Types</h4>\n                            <div class=\"analysis-item\">\n                                <h5>Evaluation Environments</h5>\n                                <ul>\n                                    <li><strong>Game-Based:</strong> StarCraft, Minecraft, Bomberman</li>\n                                    <li><strong>Simulation:</strong> Driving, inventory management</li>\n                                    <li><strong>Social Dilemmas:</strong> Cooperation vs competition</li>\n                                    <li><strong>Partial Observability:</strong> Incomplete information scenarios</li>\n                                </ul>\n                            </div>\n                        </div>\n                    </div>"
}