{
  "page": 80,
  "title": "References (Part 6)",
  "content": "<div class=\"article-header\">\n                        <div class=\"section-label\">References</div>\n                        <h1>References (Part 6)</h1>\n                    </div>\n                    <div class=\"original-content\">\n                        <h3>Continued References [77-90]</h3>\n                        <ul>\n                            <li><strong>[77]</strong> Jihwan Jeong et al. - Reflect-then-plan: Offline model-based planning through a doubly bayesian lens (2025)</li>\n                            <li><strong>[78]</strong> Shishir G Patil et al. - Gorilla: Large language model connected with massive APIs (2024)</li>\n                            <li><strong>[79]</strong> Tanmay Gupta et al. - CodeNav: Beyond tool-use to using real-world codebases with LLM agents (2024)</li>\n                            <li><strong>[80]</strong> Liyi Chen et al. - Plan-on-graph: Self-correcting adaptive planning of large language model on knowledge graphs (2024)</li>\n                            <li><strong>[81]</strong> Yanming Liu et al. - Tool-planner: Task planning with clusters across multiple tools (2024)</li>\n                            <li><strong>[82]</strong> Yichao Liang et al. - Visualpredictor: Learning abstract world models with neuro-symbolic predicates for robot planning (2024)</li>\n                            <li><strong>[83]</strong> Chan Hee Song et al. - LLMplanner: Few-shot grounded planning for embodied agents with large language models (2023)</li>\n                            <li><strong>[84]</strong> Tamer Abuelsamid et al. - Agent-c: From autonomous web navigation to foundational design principles in agentic systems (2024)</li>\n                            <li><strong>[85]</strong> Saaket Agashe et al. - Agent s: An open agentic framework that uses computers like a human (2024)</li>\n                            <li><strong>[86]</strong> Minjong Yoo et al. - Exploratory retrieval-augmented planning for continual embodied instruction following (2024)</li>\n                            <li><strong>[87]</strong> Rohan Sinha et al. - Real-time anomaly detection and reactive planning with large language models (2025)</li>\n                            <li><strong>[88]</strong> Cristina Cornelio et al. - Hierarchical planning for complex tasks with knowledge graph-rag and symbolic verification (2025)</li>\n                            <li><strong>[89]</strong> Zikang Zhou et al. - BehaviorGPT: Smart agent simulation for autonomous driving with next-patch prediction (2024)</li>\n                            <li><strong>[90]</strong> Gaoyue Zhou et al. - Dino-wm: World models on pre-trained visual features enable zero-shot planning (2024)</li>\n                        </ul>\n                    </div>\n                    <div class=\"analysis-section\">\n                        <h3>Analysis & Explanation</h3>\n                        <div class=\"analysis-block\">\n                            <h4>Planning and Tool Use References</h4>\n                            <div class=\"analysis-item\">\n                                <h5>Research Directions</h5>\n                                <ul>\n                                    <li><strong>API Integration:</strong> Gorilla, CodeNav</li>\n                                    <li><strong>Knowledge Graphs:</strong> Plan-on-graph, hierarchical planning</li>\n                                    <li><strong>Embodied Planning:</strong> LLMPlanner, retrieval-augmented</li>\n                                    <li><strong>World Models:</strong> Dino-wm, BehaviorGPT</li>\n                                </ul>\n                            </div>\n                        </div>\n                    </div>"
}