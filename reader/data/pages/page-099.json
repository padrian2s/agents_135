{
  "page": 99,
  "title": "References (Part 25)",
  "content": "<div class=\"article-header\">\n                        <div class=\"section-label\">References</div>\n                        <h1>References (Part 25)</h1>\n                    </div>\n                    <div class=\"original-content\">\n                        <h3>Continued References [324-335]</h3>\n                        <ul>\n                            <li><strong>[324]</strong> Ruihan Yang et al. - SELFGOAL: Your language agents already know how to achieve high-level goals (2025)</li>\n                            <li><strong>[325]</strong> Ajay Patel et al. - Large language models can self-improve at web agent tasks (2024)</li>\n                            <li><strong>[326]</strong> Xiaohe Bo et al. - Reflective multi-agent collaboration based on large language models (2024)</li>\n                            <li><strong>[327]</strong> Yangyang Yu et al. - Firmem: A performance-enhanced llm trading agent with layered memory and character design (2023)</li>\n                            <li><strong>[328]</strong> Yu Wang and Xi Chen - Mirix: Multi-agent memory system for llm-based agents (2025)</li>\n                            <li><strong>[329]</strong> Siru Ouyang et al. - Ragen: Understanding self-evolution in llm agents via multi-turn reinforcement learning (2025)</li>\n                            <li><strong>[330]</strong> Alireza Rezazadeh et al. - From isolated conversations to hierarchical schemas: Dynamic tree memory representation for llms (2024)</li>\n                            <li><strong>[331]</strong> Zelong Li et al. - Autoflow: Automated workflow generation for large language model agents (2024)</li>\n                            <li><strong>[332]</strong> Jayi Zhang et al. - Autoflow: Automating agentic workflow generation (2024)</li>\n                            <li><strong>[333]</strong> Zhen Zeng et al. - Flowmind: Automatic workflow generation with llms (2023)</li>\n                            <li><strong>[334]</strong> Yifei Zhou et al. - Self-challenging language model agents (2025)</li>\n                            <li><strong>[335]</strong> Weizhe Yuan et al. - Self-rewarding language models (2024)</li>\n                        </ul>\n                    </div>\n                    <div class=\"analysis-section\">\n                        <h3>Analysis & Explanation</h3>\n                        <div class=\"analysis-block\">\n                            <h4>Self-Evolution and Workflows</h4>\n                            <div class=\"analysis-item\">\n                                <h5>Key Topics</h5>\n                                <ul>\n                                    <li><strong>Self-Improvement:</strong> Autonomous agent enhancement</li>\n                                    <li><strong>Workflow Generation:</strong> Automatic task flows</li>\n                                    <li><strong>Multi-Agent:</strong> Reflective collaboration</li>\n                                </ul>\n                            </div>\n                        </div>\n                    </div>"
}